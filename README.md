# Natural Text-to-Voice Extension

**Local, privacy-first text-to-speech Chrome extension using WebGPU and Metal acceleration**

[![Status](https://img.shields.io/badge/Phase%201-Complete%20%E2%9C%85-success)]()
[![Performance](https://img.shields.io/badge/RTF-8.3x%20(short)%20%7C%2025x%20(long)-brightgreen)](native-helper/TEST_RESULTS_OPTIMIZED.md)
[![Phase](https://img.shields.io/badge/Next-Phase%202%20(Chrome%20Extension)-blue)]()

---

## Project Overview

A Chrome Manifest V3 extension providing natural text-to-speech with **production-ready native Metal acceleration** on Apple Silicon.

**Current Implementation**:
- **Kokoro-82M** (Native helper): MLX Metal-accelerated, 8.3x-25x real-time factor
  - Status: ‚úÖ **Production Ready**
  - Performance: Far exceeds 2.5x target
  - Reliability: 100% (20/20 requests, zero crashes)

**Privacy guarantee**: All processing happens locally. No data leaves your machine.

---

## Project Status

| Phase | Status | Description | Performance |
|-------|--------|-------------|-------------|
| **Phase 0** | ‚úÖ Complete | TTS.cpp validation (failed, see below) | N/A |
| **Phase 1** | ‚úÖ Complete | Native helper with MLX Kokoro-82M | **8.3x-25x RTF** |
| **Phase 2** | üîÑ In Progress | Chrome extension development | TBD |
| **Phase 3** | ‚è∏Ô∏è Planned | WebGPU in-browser fallback | TBD |

---

## Phase 1: Native Helper (COMPLETE ‚úÖ)

### Objective
Build a production-ready native macOS helper with Metal-accelerated TTS achieving ‚â•2.5x real-time factor.

### Implementation

**Architecture**:
- **Swift HTTP Server** (SwiftNIO) on localhost:random-port
- **Python MLX Worker** subprocess with Kokoro-82M
- **Communication**: Length-prefixed JSON (Native Messaging protocol)

**Optimizations Applied**:
- Phase 1: Global model caching (eliminates 1-2s reload overhead)
- Phase 2: In-memory BytesIO WAV generation (eliminates file I/O)

### Results

| Metric | Target | Achieved | Status |
|--------|--------|----------|--------|
| **RTF (short text)** | ‚â•2.5x | **8.3x** | ‚úÖ **3.3x better** |
| **RTF (long text)** | ‚â•2.5x | **25x** | ‚úÖ **10x better** |
| **Reliability** | 100% | 100% (20/20) | ‚úÖ **PASS** |
| **Audio quality** | Valid WAV | Valid WAV, 24kHz | ‚úÖ **PASS** |

**Status**: ‚úÖ **Production Ready** ‚Äî Ready for Phase 2 Chrome extension development

**See**: [native-helper/README.md](native-helper/README.md) for full documentation

---

## Phase 0: Pipeline Validation (COMPLETED ‚ö†Ô∏è)

### Objective
Validate the feasibility of TTS.cpp + Parler Mini v1.1 as the native Metal-accelerated backend for high-quality local TTS.

### Outcome
**BLOCKER**: TTS.cpp GGUF conversion incompatible with Parler v1.1 ‚Äî **pivoted to MLX Kokoro**

### What Was Tested

| Component | Version | Status |
|-----------|---------|--------|
| TTS.cpp | Oct 2025 (c04c77a) | ‚úÖ Built with Metal |
| Parler Mini | v1.1 (3.5GB) | ‚úÖ Downloaded |
| Python ML Stack | PyTorch 2.6, transformers 4.46 | ‚úÖ Configured |
| GGUF Conversion | fp16 ‚Üí Q5_0 pipeline | ‚ùå **FAILED** |

### Key Findings

#### ‚úÖ Successes
1. **TTS.cpp builds correctly** on Apple Silicon with Metal acceleration
   - Compiled binaries: `tts-cli`, `quantize`, `tts-server`
   - Metal framework detected and enabled
   - ARM64 optimizations active

2. **Parler Mini v1.1 acquired**
   - Model: 3.5GB safetensors format
   - Tokenizer: v1.1 with improved prompt parsing
   - All dependencies resolved

3. **Development environment validated**
   - Python 3.11 + 100+ ML packages
   - CMake 3.23, Xcode Command Line Tools
   - Build system functional on macOS

#### ‚ùå Blocker: GGUF Conversion Incompatibility

**Critical Issue**: TTS.cpp's GGUF export script is **incompatible with Parler Mini v1.1**

```
ValueError: Part model.0.parametrizations.weight.original0 is not in DAC_ENCODER_PARTS.
```

**Root Cause**:
- Parler v1.1 uses PyTorch's newer `weight_norm` parametrization
- This creates `parametrizations.weight.original0` tensors in the DAC audio codec
- TTS.cpp's `dac_gguf_encoder.py` expects the older flat weight structure from Parler v1.0

**Impact**: Cannot proceed with quantization (Q5_0) or Metal inference testing.

---

## Validation Conclusions

### TTS.cpp Viability Assessment

| Criterion | Status | Notes |
|-----------|--------|-------|
| **Build System** | ‚úÖ Production-ready | Clean CMake, Metal support works |
| **Model Support** | ‚ö†Ô∏è **Experimental** | Parler v1.1 unsupported; v1.0 may work |
| **Performance** | ‚è∏Ô∏è **Untested** | Blocked by conversion failure |
| **Maturity** | ‚ùå **Proof-of-Concept** | Active development, breaking changes expected |

### Recommendations

**DO NOT** proceed with TTS.cpp for MVP without one of the following:

#### Option A: Pre-Converted GGUF Models
- Test `koboldcpp/tts` or `ecyht2/parler-tts-mini-v1-GGUF`
- Likely Parler v1.0 (older tokenizer, degraded prompt accuracy)
- **Risk**: Unknown quality, may have other compatibility issues

#### Option B: Native Python Parler-TTS
- Use HuggingFace `parler-tts` library directly in helper
- **Pros**: Guaranteed compatibility, official implementation
- **Cons**: No quantization (~3.5GB RAM), larger helper binary

#### Option C: Wait for TTS.cpp Support
- Monitor [mmwillet/TTS.cpp](https://github.com/mmwillet/TTS.cpp) for Parler v1.1 patches
- **Timeline**: Unknown (repo is proof-of-concept status)

#### Option D: Pivot to Kokoro-Only MVP
- Ship WebGPU-only for v0.1
- Add Parler later once tooling matures
- **Fastest path to production**

---

## Repository Structure

```
natural-text-to-voice-extension/
‚îú‚îÄ‚îÄ README.md                           # This file (project overview)
‚îú‚îÄ‚îÄ .gitignore                          # Excludes build artifacts, models
‚îÇ
‚îú‚îÄ‚îÄ native-helper/                      # Phase 1: Production-ready helper ‚úÖ
‚îÇ   ‚îú‚îÄ‚îÄ README.md                       # Full documentation (878 lines)
‚îÇ   ‚îú‚îÄ‚îÄ QUICKSTART.md                   # 5-minute setup guide
‚îÇ   ‚îú‚îÄ‚îÄ TESTING_GUIDE.md                # Comprehensive test workflows
‚îÇ   ‚îú‚îÄ‚îÄ TEST_RESULTS_OPTIMIZED.md       # Phase 1 & 2 validation results
‚îÇ   ‚îú‚îÄ‚îÄ Package.swift                   # Swift Package Manager config
‚îÇ   ‚îú‚îÄ‚îÄ Sources/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ NaturalTTSHelper/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ main.swift              # Entry point
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ HTTPServer.swift        # SwiftNIO HTTP server
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ PythonWorker.swift      # Subprocess manager
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Config.swift            # Configuration
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Models.swift            # Data models
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ Resources/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ tts_worker.py       # Python MLX worker (optimized)
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ python-env/         # [IGNORED] Python venv
‚îÇ   ‚îú‚îÄ‚îÄ Scripts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ setup-python-env.sh         # Python setup script
‚îÇ   ‚îî‚îÄ‚îÄ Tests/
‚îÇ
‚îî‚îÄ‚îÄ chrome-extension/                   # Phase 2: Coming soon
    ‚îî‚îÄ‚îÄ (TBD)
```

**Note**: Phase 0 validation directory (`phase0-validation/`) has been removed. The TTS.cpp + Parler approach was abandoned due to GGUF conversion incompatibility. The project successfully pivoted to MLX Kokoro-82M (Phase 1 complete).

---

## Setup Instructions

### Prerequisites
- macOS with Apple Silicon (M1/M2/M3)
- Xcode Command Line Tools: `xcode-select --install`
- Python 3.9-3.11
- CMake ‚â• 3.14

### Clone with Submodules
```bash
git clone --recurse-submodules https://github.com/YOUR_USERNAME/natural-text-to-voice-extension.git
cd natural-text-to-voice-extension/phase0-validation
```

### Build TTS.cpp
```bash
cd TTS.cpp
cmake -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build --config Release -j $(sysctl -n hw.ncpu)

# Verify Metal acceleration
./build/bin/tts-cli --help | grep -i metal
```

### Download Parler Mini (Optional)
```bash
cd ..
python3 -m venv venv
source venv/bin/activate
pip install huggingface_hub

python -c "from huggingface_hub import snapshot_download; \
  snapshot_download('parler-tts/parler-tts-mini-v1.1', local_dir='models/parler-mini-v1.1')"
```

**Note**: This downloads 3.5GB. You may skip this if testing pre-converted GGUF models.

---

## Performance Targets (Untested)

Based on TTS.cpp documentation and research, **expected** performance on Apple Silicon:

| Metric | Target | Status |
|--------|--------|--------|
| Helper start | 50-200ms | ‚è∏Ô∏è Not measured |
| Model warm (Q5_0) | 1-3.5s | ‚è∏Ô∏è Not measured |
| First audio (warm) | 100-300ms | ‚è∏Ô∏è Not measured |
| Real-time factor | ~1.0x | ‚è∏Ô∏è Not measured |
| Memory (warm) | ~1-2GB | ‚è∏Ô∏è Not measured |

**These targets remain unvalidated** due to GGUF conversion failure.

---

---

## Phase 2: Chrome Extension (IN PROGRESS üîÑ)

### Objective
Build a Chrome Manifest V3 extension that integrates with the production-ready native helper.

### Planned Features

**Core Functionality**:
- [ ] Native Messaging client for IPC with helper
- [ ] Text selection context menu ("Read aloud")
- [ ] Popup UI for voice selection and settings
- [ ] Audio playback controls (play, pause, stop)
- [ ] Keyboard shortcuts for quick access

**Extension Architecture**:
- **Background Service Worker**: Native Messaging communication
- **Content Scripts**: Text selection and injection
- **Popup**: Voice settings and controls
- **Options Page**: Configuration (port, voice, speed)

**Testing**:
- [ ] Extension loads and connects to helper
- [ ] Text selection triggers TTS
- [ ] Voice selection works
- [ ] Audio plays correctly
- [ ] Native Messaging handshake succeeds

**Timeline**: TBD (now that Phase 1 is complete)

---

## Getting Started

### For Local Usage (Native Helper Only)

See [native-helper/QUICKSTART.md](native-helper/QUICKSTART.md) for a 5-minute setup guide.

**Quick start**:
```bash
# 1. Install espeak-ng
brew install espeak-ng

# 2. Setup Python environment
cd native-helper
./Scripts/setup-python-env.sh

# 3. Build and run
swift build -c release
.build/release/natural-tts-helper
```

**Performance**: 8.3x RTF (short text), 25x RTF (long text)

### For Chrome Extension Development

Coming soon (Phase 2)

---

## Documentation

| Document | Description |
|----------|-------------|
| [native-helper/README.md](native-helper/README.md) | Full native helper documentation |
| [native-helper/QUICKSTART.md](native-helper/QUICKSTART.md) | 5-minute setup guide |
| [native-helper/TESTING_GUIDE.md](native-helper/TESTING_GUIDE.md) | Comprehensive testing workflows |
| [native-helper/TEST_RESULTS_OPTIMIZED.md](native-helper/TEST_RESULTS_OPTIMIZED.md) | Phase 1 & 2 performance validation |

---

## Next Steps

1. ‚úÖ **Phase 1 Complete**: Native helper production-ready (8.3x-25x RTF)
2. üîÑ **Phase 2 Begin**: Chrome extension development
   - Implement Native Messaging client
   - Create popup UI for voice selection
   - Add content scripts for text selection
   - Integrate with helper HTTP API
3. ‚è∏Ô∏è **Phase 3 Future**: WebGPU in-browser fallback (optional)

---

## License

This project combines multiple components:

- **This repository**: MIT License (see LICENSE)
- **TTS.cpp**: MIT License - [mmwillet/TTS.cpp](https://github.com/mmwillet/TTS.cpp)
- **Parler-TTS**: Apache 2.0 - [huggingface/parler-tts](https://github.com/huggingface/parler-tts)

When distributing:
- Include TTS.cpp's LICENSE in helper binaries
- Attribute Parler-TTS per Apache 2.0 if using their models
- Do not redistribute model weights without checking HuggingFace terms

---

## Acknowledgments

- [TTS.cpp](https://github.com/mmwillet/TTS.cpp) by mmwillet - C++ TTS inference
- [Parler-TTS](https://github.com/huggingface/parler-tts) by HuggingFace - Controllable TTS model
- [GGML](https://github.com/ggerganov/ggml) - Machine learning tensor library

---

**Project Status**:
- ‚úÖ **Phase 1 Complete**: Native helper production-ready (8.3x-25x RTF)
- üîÑ **Phase 2 In Progress**: Chrome extension development
- üéØ **Current Version**: v0.2.0

**Last Updated**: 2025-11-10
**Hardware**: Apple Silicon (M1/M2/M3/M4)
**Performance**: 8.3x RTF (short text) | 25x RTF (long text)
